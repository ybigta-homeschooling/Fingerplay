{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\82104\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (2.11.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.11.0 in c:\\users\\82104\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (2.11.0)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\82104\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.23.5)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\82104\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (3.1.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\82104\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (49.2.1)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\82104\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (14.0.6)\n",
      "Requirement already satisfied: tensorboard<2.12,>=2.11 in c:\\users\\82104\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (2.11.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\82104\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.12.1)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\82104\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\82104\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\82104\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.15.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\82104\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (22.10.26)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in c:\\users\\82104\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (3.19.1)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\82104\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.1.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\82104\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (0.27.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\82104\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (21.2)\n",
      "Requirement already satisfied: keras<2.12,>=2.11.0 in c:\\users\\82104\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (2.11.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\82104\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.3.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\82104\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.41.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\82104\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.12,>=2.11.0 in c:\\users\\82104\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (2.11.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\82104\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (3.7.4.3)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\82104\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (0.4.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\82104\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.11.0->tensorflow) (0.37.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\82104\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\82104\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (3.3.4)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\82104\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (1.8.0)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\82104\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.0.2)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\82104\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\82104\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.3.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\82104\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.26.0)\n",
      "Requirement already satisfied: pyparsing<3,>=2.0.2 in c:\\users\\82104\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from packaging->tensorflow-intel==2.11.0->tensorflow) (2.4.7)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\82104\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (4.7.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\82104\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\users\\82104\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (4.2.4)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\82104\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (1.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\82104\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\82104\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\82104\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.0.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\82104\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (1.26.7)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\82104\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\82104\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (3.1.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2996, 30, 100)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions = ['rabbit', 'butterfly', 'shark']\n",
    "\n",
    "data = np.concatenate([\n",
    "    np.load('dataset/seq_rabbit_1669283552.npy'),\n",
    "    np.load('dataset/seq_butterfly_1669283552.npy'),\n",
    "    np.load('dataset/seq_shark_1669283552.npy')\n",
    "], axis=0)\n",
    "\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2996, 30, 99)\n",
      "(2996,)\n"
     ]
    }
   ],
   "source": [
    "x_data = data[:, :, :-1]\n",
    "labels = data[:, 0, -1]\n",
    "\n",
    "print(x_data.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\82104\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2996, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "y_data = to_categorical(labels, num_classes=len(actions))\n",
    "y_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2696, 30, 99) (2696, 3)\n",
      "(300, 30, 99) (300, 3)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_data = x_data.astype(np.float32)\n",
    "y_data = y_data.astype(np.float32)\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_data, y_data, test_size=0.1, random_state=2021)\n",
    "\n",
    "print(x_train.shape, y_train.shape)\n",
    "print(x_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 64)                41984     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 3)                 99        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 44,163\n",
      "Trainable params: 44,163\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "\n",
    "model = Sequential([\n",
    "    LSTM(64, activation='relu', input_shape=x_train.shape[1:3]),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(len(actions), activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "83/85 [============================>.] - ETA: 0s - loss: 5.2728 - acc: 0.6834\n",
      "Epoch 1: val_acc improved from -inf to 0.78000, saving model to models\\model.h5\n",
      "85/85 [==============================] - 4s 23ms/step - loss: 5.2080 - acc: 0.6855 - val_loss: 1.2446 - val_acc: 0.7800 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "85/85 [==============================] - ETA: 0s - loss: 1.1950 - acc: 0.8212\n",
      "Epoch 2: val_acc improved from 0.78000 to 0.88333, saving model to models\\model.h5\n",
      "85/85 [==============================] - 1s 17ms/step - loss: 1.1950 - acc: 0.8212 - val_loss: 1.2239 - val_acc: 0.8833 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.4309 - acc: 0.9121\n",
      "Epoch 3: val_acc improved from 0.88333 to 0.96333, saving model to models\\model.h5\n",
      "85/85 [==============================] - 1s 17ms/step - loss: 0.4309 - acc: 0.9121 - val_loss: 0.3308 - val_acc: 0.9633 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "84/85 [============================>.] - ETA: 0s - loss: 0.1226 - acc: 0.9628\n",
      "Epoch 4: val_acc improved from 0.96333 to 0.96667, saving model to models\\model.h5\n",
      "85/85 [==============================] - 1s 17ms/step - loss: 0.1224 - acc: 0.9629 - val_loss: 0.1047 - val_acc: 0.9667 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "84/85 [============================>.] - ETA: 0s - loss: 0.0677 - acc: 0.9758\n",
      "Epoch 5: val_acc improved from 0.96667 to 0.98667, saving model to models\\model.h5\n",
      "85/85 [==============================] - 1s 17ms/step - loss: 0.0676 - acc: 0.9759 - val_loss: 0.0364 - val_acc: 0.9867 - lr: 0.0010\n",
      "Epoch 6/200\n",
      "84/85 [============================>.] - ETA: 0s - loss: 0.0497 - acc: 0.9814\n",
      "Epoch 6: val_acc did not improve from 0.98667\n",
      "85/85 [==============================] - 1s 16ms/step - loss: 0.0496 - acc: 0.9815 - val_loss: 0.0552 - val_acc: 0.9833 - lr: 0.0010\n",
      "Epoch 7/200\n",
      "83/85 [============================>.] - ETA: 0s - loss: 0.0174 - acc: 0.9936\n",
      "Epoch 7: val_acc improved from 0.98667 to 0.99000, saving model to models\\model.h5\n",
      "85/85 [==============================] - 1s 17ms/step - loss: 0.0172 - acc: 0.9937 - val_loss: 0.0230 - val_acc: 0.9900 - lr: 0.0010\n",
      "Epoch 8/200\n",
      "82/85 [===========================>..] - ETA: 0s - loss: 0.0417 - acc: 0.9859\n",
      "Epoch 8: val_acc did not improve from 0.99000\n",
      "85/85 [==============================] - 1s 17ms/step - loss: 0.0518 - acc: 0.9841 - val_loss: 0.1276 - val_acc: 0.9500 - lr: 0.0010\n",
      "Epoch 9/200\n",
      "83/85 [============================>.] - ETA: 0s - loss: 0.0876 - acc: 0.9699\n",
      "Epoch 9: val_acc did not improve from 0.99000\n",
      "85/85 [==============================] - 2s 19ms/step - loss: 0.0880 - acc: 0.9696 - val_loss: 0.0369 - val_acc: 0.9833 - lr: 0.0010\n",
      "Epoch 10/200\n",
      "82/85 [===========================>..] - ETA: 0s - loss: 0.0294 - acc: 0.9901\n",
      "Epoch 10: val_acc improved from 0.99000 to 0.99667, saving model to models\\model.h5\n",
      "85/85 [==============================] - 2s 18ms/step - loss: 0.0292 - acc: 0.9900 - val_loss: 0.0185 - val_acc: 0.9967 - lr: 0.0010\n",
      "Epoch 11/200\n",
      "82/85 [===========================>..] - ETA: 0s - loss: 0.0141 - acc: 0.9958\n",
      "Epoch 11: val_acc improved from 0.99667 to 1.00000, saving model to models\\model.h5\n",
      "85/85 [==============================] - 2s 19ms/step - loss: 0.0141 - acc: 0.9959 - val_loss: 0.0100 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 12/200\n",
      "84/85 [============================>.] - ETA: 0s - loss: 0.0092 - acc: 0.9963\n",
      "Epoch 12: val_acc did not improve from 1.00000\n",
      "85/85 [==============================] - 1s 17ms/step - loss: 0.0092 - acc: 0.9963 - val_loss: 0.0481 - val_acc: 0.9967 - lr: 0.0010\n",
      "Epoch 13/200\n",
      "84/85 [============================>.] - ETA: 0s - loss: 0.7109 - acc: 0.9234\n",
      "Epoch 13: val_acc did not improve from 1.00000\n",
      "85/85 [==============================] - 1s 16ms/step - loss: 0.7088 - acc: 0.9236 - val_loss: 12.7053 - val_acc: 0.6233 - lr: 0.0010\n",
      "Epoch 14/200\n",
      "84/85 [============================>.] - ETA: 0s - loss: 7.3153 - acc: 0.6395\n",
      "Epoch 14: val_acc did not improve from 1.00000\n",
      "85/85 [==============================] - 1s 16ms/step - loss: 7.2947 - acc: 0.6398 - val_loss: 0.6683 - val_acc: 0.8000 - lr: 0.0010\n",
      "Epoch 15/200\n",
      "84/85 [============================>.] - ETA: 0s - loss: 0.4149 - acc: 0.8590\n",
      "Epoch 15: val_acc did not improve from 1.00000\n",
      "85/85 [==============================] - 1s 17ms/step - loss: 0.4142 - acc: 0.8591 - val_loss: 0.2791 - val_acc: 0.8700 - lr: 0.0010\n",
      "Epoch 16/200\n",
      "84/85 [============================>.] - ETA: 0s - loss: 0.2429 - acc: 0.9204\n",
      "Epoch 16: val_acc did not improve from 1.00000\n",
      "85/85 [==============================] - 1s 17ms/step - loss: 0.2423 - acc: 0.9206 - val_loss: 0.1759 - val_acc: 0.9267 - lr: 0.0010\n",
      "Epoch 17/200\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.1706 - acc: 0.9273\n",
      "Epoch 17: val_acc did not improve from 1.00000\n",
      "85/85 [==============================] - 1s 17ms/step - loss: 0.1706 - acc: 0.9273 - val_loss: 0.1165 - val_acc: 0.9467 - lr: 0.0010\n",
      "Epoch 18/200\n",
      "84/85 [============================>.] - ETA: 0s - loss: 0.1520 - acc: 0.9375\n",
      "Epoch 18: val_acc did not improve from 1.00000\n",
      "85/85 [==============================] - 1s 17ms/step - loss: 0.1518 - acc: 0.9377 - val_loss: 0.1376 - val_acc: 0.9533 - lr: 0.0010\n",
      "Epoch 19/200\n",
      "82/85 [===========================>..] - ETA: 0s - loss: 0.1131 - acc: 0.9554\n",
      "Epoch 19: val_acc did not improve from 1.00000\n",
      "85/85 [==============================] - 1s 17ms/step - loss: 0.1112 - acc: 0.9562 - val_loss: 0.0516 - val_acc: 0.9833 - lr: 0.0010\n",
      "Epoch 20/200\n",
      "83/85 [============================>.] - ETA: 0s - loss: 0.0708 - acc: 0.9718\n",
      "Epoch 20: val_acc did not improve from 1.00000\n",
      "85/85 [==============================] - 1s 17ms/step - loss: 0.0702 - acc: 0.9722 - val_loss: 0.0594 - val_acc: 0.9800 - lr: 0.0010\n",
      "Epoch 21/200\n",
      "83/85 [============================>.] - ETA: 0s - loss: 0.0786 - acc: 0.9688\n",
      "Epoch 21: val_acc did not improve from 1.00000\n",
      "85/85 [==============================] - 1s 17ms/step - loss: 0.0783 - acc: 0.9688 - val_loss: 0.0502 - val_acc: 0.9833 - lr: 0.0010\n",
      "Epoch 22/200\n",
      "83/85 [============================>.] - ETA: 0s - loss: 0.0407 - acc: 0.9823\n",
      "Epoch 22: val_acc did not improve from 1.00000\n",
      "85/85 [==============================] - 1s 17ms/step - loss: 0.0419 - acc: 0.9822 - val_loss: 0.0414 - val_acc: 0.9867 - lr: 0.0010\n",
      "Epoch 23/200\n",
      "82/85 [===========================>..] - ETA: 0s - loss: 0.0544 - acc: 0.9798\n",
      "Epoch 23: val_acc did not improve from 1.00000\n",
      "85/85 [==============================] - 1s 17ms/step - loss: 0.0535 - acc: 0.9803 - val_loss: 0.0998 - val_acc: 0.9633 - lr: 0.0010\n",
      "Epoch 24/200\n",
      "82/85 [===========================>..] - ETA: 0s - loss: 0.0434 - acc: 0.9817\n",
      "Epoch 24: val_acc did not improve from 1.00000\n",
      "85/85 [==============================] - 1s 17ms/step - loss: 0.0432 - acc: 0.9818 - val_loss: 0.0571 - val_acc: 0.9700 - lr: 0.0010\n",
      "Epoch 25/200\n",
      "84/85 [============================>.] - ETA: 0s - loss: 0.1220 - acc: 0.9643\n",
      "Epoch 25: val_acc did not improve from 1.00000\n",
      "85/85 [==============================] - 2s 18ms/step - loss: 0.1217 - acc: 0.9644 - val_loss: 0.0326 - val_acc: 0.9833 - lr: 0.0010\n",
      "Epoch 26/200\n",
      "84/85 [============================>.] - ETA: 0s - loss: 0.0290 - acc: 0.9881\n",
      "Epoch 26: val_acc did not improve from 1.00000\n",
      "85/85 [==============================] - 2s 18ms/step - loss: 0.0296 - acc: 0.9878 - val_loss: 0.0415 - val_acc: 0.9833 - lr: 0.0010\n",
      "Epoch 27/200\n",
      "84/85 [============================>.] - ETA: 0s - loss: 0.0280 - acc: 0.9862\n",
      "Epoch 27: val_acc did not improve from 1.00000\n",
      "85/85 [==============================] - 1s 17ms/step - loss: 0.0280 - acc: 0.9863 - val_loss: 0.0237 - val_acc: 0.9900 - lr: 0.0010\n",
      "Epoch 28/200\n",
      "84/85 [============================>.] - ETA: 0s - loss: 0.0191 - acc: 0.9914\n",
      "Epoch 28: val_acc did not improve from 1.00000\n",
      "85/85 [==============================] - 2s 28ms/step - loss: 0.0190 - acc: 0.9915 - val_loss: 0.0202 - val_acc: 0.9900 - lr: 0.0010\n",
      "Epoch 29/200\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.0148 - acc: 0.9926\n",
      "Epoch 29: val_acc did not improve from 1.00000\n",
      "85/85 [==============================] - 1s 16ms/step - loss: 0.0148 - acc: 0.9926 - val_loss: 0.0425 - val_acc: 0.9867 - lr: 0.0010\n",
      "Epoch 30/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84/85 [============================>.] - ETA: 0s - loss: 0.0152 - acc: 0.9933\n",
      "Epoch 30: val_acc did not improve from 1.00000\n",
      "85/85 [==============================] - 1s 17ms/step - loss: 0.0151 - acc: 0.9933 - val_loss: 0.0149 - val_acc: 0.9933 - lr: 0.0010\n",
      "Epoch 31/200\n",
      "83/85 [============================>.] - ETA: 0s - loss: 0.0142 - acc: 0.9940\n",
      "Epoch 31: val_acc did not improve from 1.00000\n",
      "85/85 [==============================] - 1s 17ms/step - loss: 0.0143 - acc: 0.9941 - val_loss: 0.0285 - val_acc: 0.9900 - lr: 0.0010\n",
      "Epoch 32/200\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.0117 - acc: 0.9955\n",
      "Epoch 32: val_acc did not improve from 1.00000\n",
      "85/85 [==============================] - 2s 23ms/step - loss: 0.0117 - acc: 0.9955 - val_loss: 0.0227 - val_acc: 0.9933 - lr: 0.0010\n",
      "Epoch 33/200\n",
      "83/85 [============================>.] - ETA: 0s - loss: 0.0051 - acc: 0.9977\n",
      "Epoch 33: val_acc did not improve from 1.00000\n",
      "85/85 [==============================] - 1s 17ms/step - loss: 0.0051 - acc: 0.9978 - val_loss: 0.0076 - val_acc: 0.9933 - lr: 0.0010\n",
      "Epoch 34/200\n",
      "83/85 [============================>.] - ETA: 0s - loss: 0.0085 - acc: 0.9962\n",
      "Epoch 34: val_acc did not improve from 1.00000\n",
      "85/85 [==============================] - 2s 18ms/step - loss: 0.0084 - acc: 0.9963 - val_loss: 0.0357 - val_acc: 0.9867 - lr: 0.0010\n",
      "Epoch 35/200\n",
      "83/85 [============================>.] - ETA: 0s - loss: 0.0066 - acc: 0.9977\n",
      "Epoch 35: val_acc did not improve from 1.00000\n",
      "85/85 [==============================] - 1s 17ms/step - loss: 0.0066 - acc: 0.9978 - val_loss: 0.0093 - val_acc: 0.9967 - lr: 0.0010\n",
      "Epoch 36/200\n",
      "84/85 [============================>.] - ETA: 0s - loss: 0.0027 - acc: 0.9993\n",
      "Epoch 36: val_acc did not improve from 1.00000\n",
      "85/85 [==============================] - 2s 18ms/step - loss: 0.0027 - acc: 0.9993 - val_loss: 0.0066 - val_acc: 0.9967 - lr: 0.0010\n",
      "Epoch 37/200\n",
      "83/85 [============================>.] - ETA: 0s - loss: 0.0112 - acc: 0.9959\n",
      "Epoch 37: val_acc did not improve from 1.00000\n",
      "85/85 [==============================] - 1s 18ms/step - loss: 0.0110 - acc: 0.9959 - val_loss: 0.1414 - val_acc: 0.9733 - lr: 0.0010\n",
      "Epoch 38/200\n",
      "84/85 [============================>.] - ETA: 0s - loss: 0.0228 - acc: 0.9929\n",
      "Epoch 38: val_acc did not improve from 1.00000\n",
      "85/85 [==============================] - 1s 17ms/step - loss: 0.0227 - acc: 0.9930 - val_loss: 0.0058 - val_acc: 0.9967 - lr: 0.0010\n",
      "Epoch 39/200\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.0443 - acc: 0.9870\n",
      "Epoch 39: val_acc did not improve from 1.00000\n",
      "85/85 [==============================] - 2s 21ms/step - loss: 0.0443 - acc: 0.9870 - val_loss: 0.0251 - val_acc: 0.9933 - lr: 0.0010\n",
      "Epoch 40/200\n",
      "84/85 [============================>.] - ETA: 0s - loss: 0.0223 - acc: 0.9911\n",
      "Epoch 40: val_acc did not improve from 1.00000\n",
      "85/85 [==============================] - 1s 16ms/step - loss: 0.0222 - acc: 0.9911 - val_loss: 0.0273 - val_acc: 0.9967 - lr: 0.0010\n",
      "Epoch 41/200\n",
      "84/85 [============================>.] - ETA: 0s - loss: 0.0079 - acc: 0.9974\n",
      "Epoch 41: val_acc did not improve from 1.00000\n",
      "85/85 [==============================] - 1s 16ms/step - loss: 0.0078 - acc: 0.9974 - val_loss: 0.0223 - val_acc: 0.9900 - lr: 0.0010\n",
      "Epoch 42/200\n",
      "82/85 [===========================>..] - ETA: 0s - loss: 0.0403 - acc: 0.9859\n",
      "Epoch 42: val_acc did not improve from 1.00000\n",
      "85/85 [==============================] - 1s 17ms/step - loss: 0.0400 - acc: 0.9859 - val_loss: 0.0121 - val_acc: 0.9967 - lr: 0.0010\n",
      "Epoch 43/200\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.0096 - acc: 0.9963\n",
      "Epoch 43: val_acc did not improve from 1.00000\n",
      "85/85 [==============================] - 1s 16ms/step - loss: 0.0096 - acc: 0.9963 - val_loss: 0.0017 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 44/200\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.0010 - acc: 0.9996\n",
      "Epoch 44: val_acc did not improve from 1.00000\n",
      "85/85 [==============================] - 1s 16ms/step - loss: 0.0010 - acc: 0.9996 - val_loss: 0.0012 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 45/200\n",
      "82/85 [===========================>..] - ETA: 0s - loss: 4.6628e-04 - acc: 1.0000\n",
      "Epoch 45: val_acc did not improve from 1.00000\n",
      "85/85 [==============================] - 1s 17ms/step - loss: 4.6018e-04 - acc: 1.0000 - val_loss: 5.7540e-04 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 46/200\n",
      "84/85 [============================>.] - ETA: 0s - loss: 3.2965e-04 - acc: 1.0000\n",
      "Epoch 46: val_acc did not improve from 1.00000\n",
      "85/85 [==============================] - 1s 16ms/step - loss: 3.2868e-04 - acc: 1.0000 - val_loss: 5.0382e-04 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 47/200\n",
      "84/85 [============================>.] - ETA: 0s - loss: 2.4149e-04 - acc: 1.0000\n",
      "Epoch 47: val_acc did not improve from 1.00000\n",
      "85/85 [==============================] - 1s 16ms/step - loss: 2.4177e-04 - acc: 1.0000 - val_loss: 4.9137e-04 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 48/200\n",
      "85/85 [==============================] - ETA: 0s - loss: 1.9211e-04 - acc: 1.0000\n",
      "Epoch 48: val_acc did not improve from 1.00000\n",
      "85/85 [==============================] - 1s 17ms/step - loss: 1.9211e-04 - acc: 1.0000 - val_loss: 0.0033 - val_acc: 0.9967 - lr: 0.0010\n",
      "Epoch 49/200\n",
      "82/85 [===========================>..] - ETA: 0s - loss: 2.0260e-04 - acc: 1.0000\n",
      "Epoch 49: val_acc did not improve from 1.00000\n",
      "85/85 [==============================] - 1s 17ms/step - loss: 1.9995e-04 - acc: 1.0000 - val_loss: 9.5778e-04 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 50/200\n",
      "83/85 [============================>.] - ETA: 0s - loss: 1.2332e-04 - acc: 1.0000\n",
      "Epoch 50: val_acc did not improve from 1.00000\n",
      "85/85 [==============================] - 1s 16ms/step - loss: 1.2257e-04 - acc: 1.0000 - val_loss: 4.7080e-04 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 51/200\n",
      "85/85 [==============================] - ETA: 0s - loss: 9.7533e-05 - acc: 1.0000\n",
      "Epoch 51: val_acc did not improve from 1.00000\n",
      "85/85 [==============================] - 1s 16ms/step - loss: 9.7533e-05 - acc: 1.0000 - val_loss: 4.7842e-04 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 52/200\n",
      "85/85 [==============================] - ETA: 0s - loss: 8.6117e-05 - acc: 1.0000\n",
      "Epoch 52: val_acc did not improve from 1.00000\n",
      "85/85 [==============================] - 2s 18ms/step - loss: 8.6117e-05 - acc: 1.0000 - val_loss: 5.9043e-04 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 53/200\n",
      "85/85 [==============================] - ETA: 0s - loss: 7.7248e-05 - acc: 1.0000\n",
      "Epoch 53: val_acc did not improve from 1.00000\n",
      "85/85 [==============================] - 2s 20ms/step - loss: 7.7248e-05 - acc: 1.0000 - val_loss: 9.2941e-04 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 54/200\n",
      "85/85 [==============================] - ETA: 0s - loss: 7.0741e-05 - acc: 1.0000\n",
      "Epoch 54: val_acc did not improve from 1.00000\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 7.0741e-05 - acc: 1.0000 - val_loss: 7.2563e-04 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 55/200\n",
      "84/85 [============================>.] - ETA: 0s - loss: 6.2147e-05 - acc: 1.0000\n",
      "Epoch 55: val_acc did not improve from 1.00000\n",
      "85/85 [==============================] - 2s 19ms/step - loss: 6.1973e-05 - acc: 1.0000 - val_loss: 0.0046 - val_acc: 0.9967 - lr: 0.0010\n",
      "Epoch 56/200\n",
      "84/85 [============================>.] - ETA: 0s - loss: 6.1451e-05 - acc: 1.0000\n",
      "Epoch 56: val_acc did not improve from 1.00000\n",
      "85/85 [==============================] - 1s 16ms/step - loss: 6.1276e-05 - acc: 1.0000 - val_loss: 0.0016 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 57/200\n",
      "84/85 [============================>.] - ETA: 0s - loss: 5.3230e-05 - acc: 1.0000\n",
      "Epoch 57: val_acc did not improve from 1.00000\n",
      "85/85 [==============================] - 1s 16ms/step - loss: 5.3081e-05 - acc: 1.0000 - val_loss: 0.0027 - val_acc: 0.9967 - lr: 0.0010\n",
      "Epoch 58/200\n",
      "83/85 [============================>.] - ETA: 0s - loss: 4.7257e-05 - acc: 1.0000\n",
      "Epoch 58: val_acc did not improve from 1.00000\n",
      "85/85 [==============================] - 1s 16ms/step - loss: 4.7674e-05 - acc: 1.0000 - val_loss: 7.1898e-04 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 59/200\n",
      "84/85 [============================>.] - ETA: 0s - loss: 4.6263e-05 - acc: 1.0000\n",
      "Epoch 59: val_acc did not improve from 1.00000\n",
      "85/85 [==============================] - 1s 17ms/step - loss: 4.6126e-05 - acc: 1.0000 - val_loss: 0.0020 - val_acc: 1.0000 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/200\n",
      "83/85 [============================>.] - ETA: 0s - loss: 4.2168e-05 - acc: 1.0000\n",
      "Epoch 60: val_acc did not improve from 1.00000\n",
      "85/85 [==============================] - 1s 16ms/step - loss: 4.1588e-05 - acc: 1.0000 - val_loss: 0.0027 - val_acc: 0.9967 - lr: 0.0010\n",
      "Epoch 61/200\n",
      "85/85 [==============================] - ETA: 0s - loss: 3.8441e-05 - acc: 1.0000\n",
      "Epoch 61: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 61: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "85/85 [==============================] - 1s 17ms/step - loss: 3.8441e-05 - acc: 1.0000 - val_loss: 0.0032 - val_acc: 0.9967 - lr: 0.0010\n",
      "Epoch 62/200\n",
      "84/85 [============================>.] - ETA: 0s - loss: 3.6329e-05 - acc: 1.0000\n",
      "Epoch 62: val_acc did not improve from 1.00000\n",
      "85/85 [==============================] - 1s 17ms/step - loss: 3.6221e-05 - acc: 1.0000 - val_loss: 0.0025 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 63/200\n",
      "83/85 [============================>.] - ETA: 0s - loss: 3.5412e-05 - acc: 1.0000\n",
      "Epoch 63: val_acc did not improve from 1.00000\n",
      "85/85 [==============================] - 1s 18ms/step - loss: 3.5124e-05 - acc: 1.0000 - val_loss: 0.0014 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 64/200\n",
      "82/85 [===========================>..] - ETA: 0s - loss: 3.3534e-05 - acc: 1.0000\n",
      "Epoch 64: val_acc did not improve from 1.00000\n",
      "85/85 [==============================] - 1s 17ms/step - loss: 3.3214e-05 - acc: 1.0000 - val_loss: 0.0023 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 65/200\n",
      "83/85 [============================>.] - ETA: 0s - loss: 3.2056e-05 - acc: 1.0000\n",
      "Epoch 65: val_acc did not improve from 1.00000\n",
      "85/85 [==============================] - 1s 17ms/step - loss: 3.1947e-05 - acc: 1.0000 - val_loss: 0.0024 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 66/200\n",
      "82/85 [===========================>..] - ETA: 0s - loss: 3.1247e-05 - acc: 1.0000\n",
      "Epoch 66: val_acc did not improve from 1.00000\n",
      "85/85 [==============================] - 1s 16ms/step - loss: 3.0873e-05 - acc: 1.0000 - val_loss: 0.0020 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 67/200\n",
      "82/85 [===========================>..] - ETA: 0s - loss: 3.0787e-05 - acc: 1.0000\n",
      "Epoch 67: val_acc did not improve from 1.00000\n",
      "85/85 [==============================] - 1s 17ms/step - loss: 3.0180e-05 - acc: 1.0000 - val_loss: 0.0024 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 68/200\n",
      "85/85 [==============================] - ETA: 0s - loss: 2.8507e-05 - acc: 1.0000\n",
      "Epoch 68: val_acc did not improve from 1.00000\n",
      "85/85 [==============================] - 2s 18ms/step - loss: 2.8507e-05 - acc: 1.0000 - val_loss: 0.0031 - val_acc: 0.9967 - lr: 5.0000e-04\n",
      "Epoch 69/200\n",
      "84/85 [============================>.] - ETA: 0s - loss: 2.7719e-05 - acc: 1.0000\n",
      "Epoch 69: val_acc did not improve from 1.00000\n",
      "85/85 [==============================] - 1s 16ms/step - loss: 2.7752e-05 - acc: 1.0000 - val_loss: 0.0025 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 70/200\n",
      "82/85 [===========================>..] - ETA: 0s - loss: 2.7010e-05 - acc: 1.0000\n",
      "Epoch 70: val_acc did not improve from 1.00000\n",
      "85/85 [==============================] - 1s 17ms/step - loss: 2.6655e-05 - acc: 1.0000 - val_loss: 0.0022 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 71/200\n",
      "85/85 [==============================] - ETA: 0s - loss: 2.5605e-05 - acc: 1.0000\n",
      "Epoch 71: val_acc did not improve from 1.00000\n",
      "85/85 [==============================] - 1s 17ms/step - loss: 2.5605e-05 - acc: 1.0000 - val_loss: 0.0024 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 72/200\n",
      "82/85 [===========================>..] - ETA: 0s - loss: 2.5022e-05 - acc: 1.0000\n",
      "Epoch 72: val_acc did not improve from 1.00000\n",
      "85/85 [==============================] - 1s 17ms/step - loss: 2.4441e-05 - acc: 1.0000 - val_loss: 0.0031 - val_acc: 0.9967 - lr: 5.0000e-04\n",
      "Epoch 73/200\n",
      "83/85 [============================>.] - ETA: 0s - loss: 2.4108e-05 - acc: 1.0000\n",
      "Epoch 73: val_acc did not improve from 1.00000\n",
      "85/85 [==============================] - 1s 17ms/step - loss: 2.3869e-05 - acc: 1.0000 - val_loss: 0.0026 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 74/200\n",
      "84/85 [============================>.] - ETA: 0s - loss: 2.3070e-05 - acc: 1.0000\n",
      "Epoch 74: val_acc did not improve from 1.00000\n",
      "85/85 [==============================] - 1s 17ms/step - loss: 2.3009e-05 - acc: 1.0000 - val_loss: 0.0039 - val_acc: 0.9967 - lr: 5.0000e-04\n",
      "Epoch 75/200\n",
      "85/85 [==============================] - ETA: 0s - loss: 2.1918e-05 - acc: 1.0000\n",
      "Epoch 75: val_acc did not improve from 1.00000\n",
      "85/85 [==============================] - 1s 17ms/step - loss: 2.1918e-05 - acc: 1.0000 - val_loss: 0.0039 - val_acc: 0.9967 - lr: 5.0000e-04\n",
      "Epoch 76/200\n",
      "84/85 [============================>.] - ETA: 0s - loss: 2.0646e-05 - acc: 1.0000\n",
      "Epoch 76: val_acc did not improve from 1.00000\n",
      "85/85 [==============================] - 1s 17ms/step - loss: 2.0968e-05 - acc: 1.0000 - val_loss: 0.0029 - val_acc: 0.9967 - lr: 5.0000e-04\n",
      "Epoch 77/200\n",
      "84/85 [============================>.] - ETA: 0s - loss: 2.0230e-05 - acc: 1.0000\n",
      "Epoch 77: val_acc did not improve from 1.00000\n",
      "85/85 [==============================] - 1s 17ms/step - loss: 2.0219e-05 - acc: 1.0000 - val_loss: 0.0031 - val_acc: 0.9967 - lr: 5.0000e-04\n",
      "Epoch 78/200\n",
      "85/85 [==============================] - ETA: 0s - loss: 1.9653e-05 - acc: 1.0000\n",
      "Epoch 78: val_acc did not improve from 1.00000\n",
      "85/85 [==============================] - 1s 17ms/step - loss: 1.9653e-05 - acc: 1.0000 - val_loss: 0.0042 - val_acc: 0.9967 - lr: 5.0000e-04\n",
      "Epoch 79/200\n",
      "82/85 [===========================>..] - ETA: 0s - loss: 1.5847e-05 - acc: 1.0000\n",
      "Epoch 79: val_acc did not improve from 1.00000\n",
      "85/85 [==============================] - 1s 17ms/step - loss: 1.9429e-05 - acc: 1.0000 - val_loss: 0.0024 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 80/200\n",
      "84/85 [============================>.] - ETA: 0s - loss: 1.7822e-05 - acc: 1.0000\n",
      "Epoch 80: val_acc did not improve from 1.00000\n",
      "85/85 [==============================] - 1s 17ms/step - loss: 1.7771e-05 - acc: 1.0000 - val_loss: 0.0037 - val_acc: 0.9967 - lr: 5.0000e-04\n",
      "Epoch 81/200\n",
      "83/85 [============================>.] - ETA: 0s - loss: 1.7220e-05 - acc: 1.0000\n",
      "Epoch 81: val_acc did not improve from 1.00000\n",
      "85/85 [==============================] - 1s 16ms/step - loss: 1.6994e-05 - acc: 1.0000 - val_loss: 0.0029 - val_acc: 0.9967 - lr: 5.0000e-04\n",
      "Epoch 82/200\n",
      "84/85 [============================>.] - ETA: 0s - loss: 1.6604e-05 - acc: 1.0000\n",
      "Epoch 82: val_acc did not improve from 1.00000\n",
      "85/85 [==============================] - 1s 17ms/step - loss: 1.6558e-05 - acc: 1.0000 - val_loss: 0.0030 - val_acc: 0.9967 - lr: 5.0000e-04\n",
      "Epoch 83/200\n",
      "82/85 [===========================>..] - ETA: 0s - loss: 1.4957e-05 - acc: 1.0000\n",
      "Epoch 83: val_acc did not improve from 1.00000\n",
      "85/85 [==============================] - 1s 17ms/step - loss: 1.5977e-05 - acc: 1.0000 - val_loss: 0.0044 - val_acc: 0.9967 - lr: 5.0000e-04\n",
      "Epoch 84/200\n",
      "82/85 [===========================>..] - ETA: 0s - loss: 1.5662e-05 - acc: 1.0000\n",
      "Epoch 84: val_acc did not improve from 1.00000\n",
      "85/85 [==============================] - 1s 17ms/step - loss: 1.5311e-05 - acc: 1.0000 - val_loss: 0.0041 - val_acc: 0.9967 - lr: 5.0000e-04\n",
      "Epoch 85/200\n",
      "85/85 [==============================] - ETA: 0s - loss: 1.4633e-05 - acc: 1.0000\n",
      "Epoch 85: val_acc did not improve from 1.00000\n",
      "85/85 [==============================] - 1s 17ms/step - loss: 1.4633e-05 - acc: 1.0000 - val_loss: 0.0040 - val_acc: 0.9967 - lr: 5.0000e-04\n",
      "Epoch 86/200\n",
      "84/85 [============================>.] - ETA: 0s - loss: 1.3886e-05 - acc: 1.0000\n",
      "Epoch 86: val_acc did not improve from 1.00000\n",
      "85/85 [==============================] - 1s 17ms/step - loss: 1.3845e-05 - acc: 1.0000 - val_loss: 0.0034 - val_acc: 0.9967 - lr: 5.0000e-04\n",
      "Epoch 87/200\n",
      "84/85 [============================>.] - ETA: 0s - loss: 1.3508e-05 - acc: 1.0000\n",
      "Epoch 87: val_acc did not improve from 1.00000\n",
      "85/85 [==============================] - 1s 16ms/step - loss: 1.3471e-05 - acc: 1.0000 - val_loss: 0.0023 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 88/200\n",
      "84/85 [============================>.] - ETA: 0s - loss: 1.3062e-05 - acc: 1.0000\n",
      "Epoch 88: val_acc did not improve from 1.00000\n",
      "85/85 [==============================] - 1s 16ms/step - loss: 1.3023e-05 - acc: 1.0000 - val_loss: 0.0025 - val_acc: 1.0000 - lr: 5.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89/200\n",
      "82/85 [===========================>..] - ETA: 0s - loss: 1.2480e-05 - acc: 1.0000\n",
      "Epoch 89: val_acc did not improve from 1.00000\n",
      "85/85 [==============================] - 1s 17ms/step - loss: 1.2493e-05 - acc: 1.0000 - val_loss: 0.0035 - val_acc: 0.9967 - lr: 5.0000e-04\n",
      "Epoch 90/200\n",
      "85/85 [==============================] - ETA: 0s - loss: 1.1762e-05 - acc: 1.0000\n",
      "Epoch 90: val_acc did not improve from 1.00000\n",
      "85/85 [==============================] - 1s 16ms/step - loss: 1.1762e-05 - acc: 1.0000 - val_loss: 0.0028 - val_acc: 0.9967 - lr: 5.0000e-04\n",
      "Epoch 91/200\n",
      "85/85 [==============================] - ETA: 0s - loss: 1.1434e-05 - acc: 1.0000\n",
      "Epoch 91: val_acc did not improve from 1.00000\n",
      "85/85 [==============================] - 1s 16ms/step - loss: 1.1434e-05 - acc: 1.0000 - val_loss: 0.0023 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 92/200\n",
      "85/85 [==============================] - ETA: 0s - loss: 1.1201e-05 - acc: 1.0000\n",
      "Epoch 92: val_acc did not improve from 1.00000\n",
      "85/85 [==============================] - 1s 16ms/step - loss: 1.1201e-05 - acc: 1.0000 - val_loss: 0.0025 - val_acc: 0.9967 - lr: 5.0000e-04\n",
      "Epoch 93/200\n",
      "85/85 [==============================] - ETA: 0s - loss: 1.0661e-05 - acc: 1.0000\n",
      "Epoch 93: val_acc did not improve from 1.00000\n",
      "85/85 [==============================] - 1s 17ms/step - loss: 1.0661e-05 - acc: 1.0000 - val_loss: 0.0021 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 94/200\n",
      "82/85 [===========================>..] - ETA: 0s - loss: 1.0435e-05 - acc: 1.0000\n",
      "Epoch 94: val_acc did not improve from 1.00000\n",
      "85/85 [==============================] - 1s 17ms/step - loss: 1.0202e-05 - acc: 1.0000 - val_loss: 0.0034 - val_acc: 0.9967 - lr: 5.0000e-04\n",
      "Epoch 95/200\n",
      "85/85 [==============================] - ETA: 0s - loss: 9.7814e-06 - acc: 1.0000\n",
      "Epoch 95: val_acc did not improve from 1.00000\n",
      "85/85 [==============================] - 1s 17ms/step - loss: 9.7814e-06 - acc: 1.0000 - val_loss: 0.0016 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 96/200\n",
      "84/85 [============================>.] - ETA: 0s - loss: 9.5628e-06 - acc: 1.0000\n",
      "Epoch 96: val_acc did not improve from 1.00000\n",
      "85/85 [==============================] - 1s 16ms/step - loss: 9.5345e-06 - acc: 1.0000 - val_loss: 0.0022 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 97/200\n",
      "82/85 [===========================>..] - ETA: 0s - loss: 9.2941e-06 - acc: 1.0000\n",
      "Epoch 97: val_acc did not improve from 1.00000\n",
      "85/85 [==============================] - 1s 17ms/step - loss: 9.1550e-06 - acc: 1.0000 - val_loss: 0.0021 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 98/200\n",
      "83/85 [============================>.] - ETA: 0s - loss: 8.8562e-06 - acc: 1.0000\n",
      "Epoch 98: val_acc did not improve from 1.00000\n",
      "85/85 [==============================] - 1s 16ms/step - loss: 8.7520e-06 - acc: 1.0000 - val_loss: 0.0022 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 99/200\n",
      "85/85 [==============================] - ETA: 0s - loss: 8.3669e-06 - acc: 1.0000\n",
      "Epoch 99: val_acc did not improve from 1.00000\n",
      "85/85 [==============================] - 1s 16ms/step - loss: 8.3669e-06 - acc: 1.0000 - val_loss: 0.0025 - val_acc: 0.9967 - lr: 5.0000e-04\n",
      "Epoch 100/200\n",
      "84/85 [============================>.] - ETA: 0s - loss: 8.1985e-06 - acc: 1.0000\n",
      "Epoch 100: val_acc did not improve from 1.00000\n",
      "85/85 [==============================] - 1s 17ms/step - loss: 8.1747e-06 - acc: 1.0000 - val_loss: 0.0044 - val_acc: 0.9967 - lr: 5.0000e-04\n",
      "Epoch 101/200\n",
      "83/85 [============================>.] - ETA: 0s - loss: 7.6588e-06 - acc: 1.0000\n",
      "Epoch 101: val_acc did not improve from 1.00000\n",
      "85/85 [==============================] - 1s 16ms/step - loss: 7.6864e-06 - acc: 1.0000 - val_loss: 0.0019 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 102/200\n",
      "83/85 [============================>.] - ETA: 0s - loss: 7.4913e-06 - acc: 1.0000\n",
      "Epoch 102: val_acc did not improve from 1.00000\n",
      "85/85 [==============================] - 1s 17ms/step - loss: 7.4214e-06 - acc: 1.0000 - val_loss: 0.0038 - val_acc: 0.9967 - lr: 5.0000e-04\n",
      "Epoch 103/200\n",
      "84/85 [============================>.] - ETA: 0s - loss: 7.2498e-06 - acc: 1.0000\n",
      "Epoch 103: val_acc did not improve from 1.00000\n",
      "85/85 [==============================] - 1s 17ms/step - loss: 7.2283e-06 - acc: 1.0000 - val_loss: 0.0031 - val_acc: 0.9967 - lr: 5.0000e-04\n",
      "Epoch 104/200\n",
      "85/85 [==============================] - ETA: 0s - loss: 6.9302e-06 - acc: 1.0000\n",
      "Epoch 104: val_acc did not improve from 1.00000\n",
      "85/85 [==============================] - 1s 17ms/step - loss: 6.9302e-06 - acc: 1.0000 - val_loss: 0.0034 - val_acc: 0.9967 - lr: 5.0000e-04\n",
      "Epoch 105/200\n",
      "82/85 [===========================>..] - ETA: 0s - loss: 6.5208e-06 - acc: 1.0000\n",
      "Epoch 105: val_acc did not improve from 1.00000\n",
      "85/85 [==============================] - 1s 17ms/step - loss: 6.5300e-06 - acc: 1.0000 - val_loss: 0.0028 - val_acc: 0.9967 - lr: 5.0000e-04\n",
      "Epoch 106/200\n",
      "84/85 [============================>.] - ETA: 0s - loss: 6.3463e-06 - acc: 1.0000\n",
      "Epoch 106: val_acc did not improve from 1.00000\n",
      "85/85 [==============================] - 1s 16ms/step - loss: 6.3275e-06 - acc: 1.0000 - val_loss: 7.6902e-04 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 107/200\n",
      "84/85 [============================>.] - ETA: 0s - loss: 6.1776e-06 - acc: 1.0000\n",
      "Epoch 107: val_acc did not improve from 1.00000\n",
      "85/85 [==============================] - 1s 17ms/step - loss: 6.1627e-06 - acc: 1.0000 - val_loss: 0.0022 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 108/200\n",
      "83/85 [============================>.] - ETA: 0s - loss: 5.8612e-06 - acc: 1.0000\n",
      "Epoch 108: val_acc did not improve from 1.00000\n",
      "85/85 [==============================] - 1s 17ms/step - loss: 5.7753e-06 - acc: 1.0000 - val_loss: 0.0023 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 109/200\n",
      "84/85 [============================>.] - ETA: 0s - loss: 5.4905e-06 - acc: 1.0000\n",
      "Epoch 109: val_acc did not improve from 1.00000\n",
      "85/85 [==============================] - 1s 17ms/step - loss: 5.4758e-06 - acc: 1.0000 - val_loss: 0.0032 - val_acc: 0.9967 - lr: 5.0000e-04\n",
      "Epoch 110/200\n",
      "83/85 [============================>.] - ETA: 0s - loss: 5.4189e-06 - acc: 1.0000\n",
      "Epoch 110: val_acc did not improve from 1.00000\n",
      "85/85 [==============================] - 1s 16ms/step - loss: 5.3853e-06 - acc: 1.0000 - val_loss: 0.0029 - val_acc: 0.9967 - lr: 5.0000e-04\n",
      "Epoch 111/200\n",
      "85/85 [==============================] - ETA: 0s - loss: 5.0945e-06 - acc: 1.0000\n",
      "Epoch 111: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 111: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "85/85 [==============================] - 1s 17ms/step - loss: 5.0945e-06 - acc: 1.0000 - val_loss: 0.0025 - val_acc: 0.9967 - lr: 5.0000e-04\n",
      "Epoch 112/200\n",
      "82/85 [===========================>..] - ETA: 0s - loss: 4.7816e-06 - acc: 1.0000\n",
      "Epoch 112: val_acc did not improve from 1.00000\n",
      "85/85 [==============================] - 1s 17ms/step - loss: 4.8408e-06 - acc: 1.0000 - val_loss: 0.0023 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 113/200\n",
      "85/85 [==============================] - ETA: 0s - loss: 4.7087e-06 - acc: 1.0000\n",
      "Epoch 113: val_acc did not improve from 1.00000\n",
      "85/85 [==============================] - 1s 17ms/step - loss: 4.7087e-06 - acc: 1.0000 - val_loss: 0.0021 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 114/200\n",
      "82/85 [===========================>..] - ETA: 0s - loss: 4.7072e-06 - acc: 1.0000\n",
      "Epoch 114: val_acc did not improve from 1.00000\n",
      "85/85 [==============================] - 1s 17ms/step - loss: 4.6564e-06 - acc: 1.0000 - val_loss: 0.0032 - val_acc: 0.9967 - lr: 2.5000e-04\n",
      "Epoch 115/200\n",
      "84/85 [============================>.] - ETA: 0s - loss: 4.5326e-06 - acc: 1.0000\n",
      "Epoch 115: val_acc did not improve from 1.00000\n",
      "85/85 [==============================] - 1s 16ms/step - loss: 4.5223e-06 - acc: 1.0000 - val_loss: 0.0031 - val_acc: 0.9967 - lr: 2.5000e-04\n",
      "Epoch 116/200\n",
      "83/85 [============================>.] - ETA: 0s - loss: 4.3444e-06 - acc: 1.0000\n",
      "Epoch 116: val_acc did not improve from 1.00000\n",
      "85/85 [==============================] - 1s 16ms/step - loss: 4.3927e-06 - acc: 1.0000 - val_loss: 0.0020 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 117/200\n",
      "83/85 [============================>.] - ETA: 0s - loss: 4.3391e-06 - acc: 1.0000\n",
      "Epoch 117: val_acc did not improve from 1.00000\n",
      "85/85 [==============================] - 1s 17ms/step - loss: 4.3111e-06 - acc: 1.0000 - val_loss: 0.0035 - val_acc: 0.9967 - lr: 2.5000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 118/200\n",
      "82/85 [===========================>..] - ETA: 0s - loss: 4.0632e-06 - acc: 1.0000\n",
      "Epoch 118: val_acc did not improve from 1.00000\n",
      "85/85 [==============================] - 1s 17ms/step - loss: 4.2169e-06 - acc: 1.0000 - val_loss: 0.0030 - val_acc: 0.9967 - lr: 2.5000e-04\n",
      "Epoch 119/200\n",
      "85/85 [==============================] - ETA: 0s - loss: 4.0907e-06 - acc: 1.0000\n",
      "Epoch 119: val_acc did not improve from 1.00000\n",
      "85/85 [==============================] - 1s 17ms/step - loss: 4.0907e-06 - acc: 1.0000 - val_loss: 0.0021 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 120/200\n",
      "85/85 [==============================] - ETA: 0s - loss: 3.9984e-06 - acc: 1.0000\n",
      "Epoch 120: val_acc did not improve from 1.00000\n",
      "85/85 [==============================] - 1s 16ms/step - loss: 3.9984e-06 - acc: 1.0000 - val_loss: 0.0018 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 121/200\n",
      "85/85 [==============================] - ETA: 0s - loss: 3.9077e-06 - acc: 1.0000\n",
      "Epoch 121: val_acc did not improve from 1.00000\n",
      "85/85 [==============================] - 1s 17ms/step - loss: 3.9077e-06 - acc: 1.0000 - val_loss: 0.0029 - val_acc: 0.9967 - lr: 2.5000e-04\n",
      "Epoch 122/200\n",
      "85/85 [==============================] - ETA: 0s - loss: 3.7499e-06 - acc: 1.0000\n",
      "Epoch 122: val_acc did not improve from 1.00000\n",
      "85/85 [==============================] - 1s 17ms/step - loss: 3.7499e-06 - acc: 1.0000 - val_loss: 0.0034 - val_acc: 0.9967 - lr: 2.5000e-04\n",
      "Epoch 123/200\n",
      "83/85 [============================>.] - ETA: 0s - loss: 3.7871e-06 - acc: 1.0000\n",
      "Epoch 123: val_acc did not improve from 1.00000\n",
      "85/85 [==============================] - 1s 17ms/step - loss: 3.7356e-06 - acc: 1.0000 - val_loss: 0.0027 - val_acc: 0.9967 - lr: 2.5000e-04\n",
      "Epoch 124/200\n",
      "82/85 [===========================>..] - ETA: 0s - loss: 3.5040e-06 - acc: 1.0000\n",
      "Epoch 124: val_acc did not improve from 1.00000\n",
      "85/85 [==============================] - 1s 17ms/step - loss: 3.5550e-06 - acc: 1.0000 - val_loss: 0.0034 - val_acc: 0.9967 - lr: 2.5000e-04\n",
      "Epoch 125/200\n",
      "84/85 [============================>.] - ETA: 0s - loss: 3.4834e-06 - acc: 1.0000\n",
      "Epoch 125: val_acc did not improve from 1.00000\n",
      "85/85 [==============================] - 1s 16ms/step - loss: 3.4732e-06 - acc: 1.0000 - val_loss: 0.0033 - val_acc: 0.9967 - lr: 2.5000e-04\n",
      "Epoch 126/200\n",
      "82/85 [===========================>..] - ETA: 0s - loss: 3.2568e-06 - acc: 1.0000\n",
      "Epoch 126: val_acc did not improve from 1.00000\n",
      "85/85 [==============================] - 1s 17ms/step - loss: 3.3019e-06 - acc: 1.0000 - val_loss: 0.0025 - val_acc: 0.9967 - lr: 2.5000e-04\n",
      "Epoch 127/200\n",
      "84/85 [============================>.] - ETA: 0s - loss: 3.1880e-06 - acc: 1.0000\n",
      "Epoch 127: val_acc did not improve from 1.00000\n",
      "85/85 [==============================] - 1s 17ms/step - loss: 3.1786e-06 - acc: 1.0000 - val_loss: 0.0041 - val_acc: 0.9967 - lr: 2.5000e-04\n",
      "Epoch 128/200\n",
      "84/85 [============================>.] - ETA: 0s - loss: 3.0983e-06 - acc: 1.0000\n",
      "Epoch 128: val_acc did not improve from 1.00000\n",
      "85/85 [==============================] - 1s 17ms/step - loss: 3.0894e-06 - acc: 1.0000 - val_loss: 0.0021 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 129/200\n",
      "84/85 [============================>.] - ETA: 0s - loss: 3.0490e-06 - acc: 1.0000\n",
      "Epoch 129: val_acc did not improve from 1.00000\n",
      "85/85 [==============================] - 1s 17ms/step - loss: 3.0402e-06 - acc: 1.0000 - val_loss: 0.0014 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 130/200\n",
      "84/85 [============================>.] - ETA: 0s - loss: 2.9129e-06 - acc: 1.0000\n",
      "Epoch 130: val_acc did not improve from 1.00000\n",
      "85/85 [==============================] - 1s 17ms/step - loss: 2.9047e-06 - acc: 1.0000 - val_loss: 0.0025 - val_acc: 0.9967 - lr: 2.5000e-04\n",
      "Epoch 131/200\n",
      "85/85 [==============================] - ETA: 0s - loss: 2.8407e-06 - acc: 1.0000\n",
      "Epoch 131: val_acc did not improve from 1.00000\n",
      "85/85 [==============================] - 1s 16ms/step - loss: 2.8407e-06 - acc: 1.0000 - val_loss: 0.0030 - val_acc: 0.9967 - lr: 2.5000e-04\n",
      "Epoch 132/200\n",
      "82/85 [===========================>..] - ETA: 0s - loss: 2.7940e-06 - acc: 1.0000\n",
      "Epoch 132: val_acc did not improve from 1.00000\n",
      "85/85 [==============================] - 1s 17ms/step - loss: 2.8167e-06 - acc: 1.0000 - val_loss: 0.0029 - val_acc: 0.9967 - lr: 2.5000e-04\n",
      "Epoch 133/200\n",
      "85/85 [==============================] - ETA: 0s - loss: 2.6180e-06 - acc: 1.0000\n",
      "Epoch 133: val_acc did not improve from 1.00000\n",
      "85/85 [==============================] - 1s 16ms/step - loss: 2.6180e-06 - acc: 1.0000 - val_loss: 0.0035 - val_acc: 0.9967 - lr: 2.5000e-04\n",
      "Epoch 134/200\n",
      "84/85 [============================>.] - ETA: 0s - loss: 2.4204e-06 - acc: 1.0000\n",
      "Epoch 134: val_acc did not improve from 1.00000\n",
      "85/85 [==============================] - 1s 16ms/step - loss: 2.4606e-06 - acc: 1.0000 - val_loss: 0.0017 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 135/200\n",
      "84/85 [============================>.] - ETA: 0s - loss: 2.3926e-06 - acc: 1.0000\n",
      "Epoch 135: val_acc did not improve from 1.00000\n",
      "85/85 [==============================] - 1s 16ms/step - loss: 2.4294e-06 - acc: 1.0000 - val_loss: 0.0021 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 136/200\n",
      "85/85 [==============================] - ETA: 0s - loss: 2.2907e-06 - acc: 1.0000\n",
      "Epoch 136: val_acc did not improve from 1.00000\n",
      "85/85 [==============================] - 1s 17ms/step - loss: 2.2907e-06 - acc: 1.0000 - val_loss: 0.0040 - val_acc: 0.9967 - lr: 2.5000e-04\n",
      "Epoch 137/200\n",
      "83/85 [============================>.] - ETA: 0s - loss: 2.2483e-06 - acc: 1.0000\n",
      "Epoch 137: val_acc did not improve from 1.00000\n",
      "85/85 [==============================] - 1s 17ms/step - loss: 2.2182e-06 - acc: 1.0000 - val_loss: 0.0033 - val_acc: 0.9967 - lr: 2.5000e-04\n",
      "Epoch 138/200\n",
      "85/85 [==============================] - ETA: 0s - loss: 2.1204e-06 - acc: 1.0000\n",
      "Epoch 138: val_acc did not improve from 1.00000\n",
      "85/85 [==============================] - 1s 16ms/step - loss: 2.1204e-06 - acc: 1.0000 - val_loss: 0.0025 - val_acc: 0.9967 - lr: 2.5000e-04\n",
      "Epoch 139/200\n",
      "83/85 [============================>.] - ETA: 0s - loss: 2.0215e-06 - acc: 1.0000\n",
      "Epoch 139: val_acc did not improve from 1.00000\n",
      "85/85 [==============================] - 1s 17ms/step - loss: 2.0228e-06 - acc: 1.0000 - val_loss: 0.0022 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 140/200\n",
      "85/85 [==============================] - ETA: 0s - loss: 1.9456e-06 - acc: 1.0000\n",
      "Epoch 140: val_acc did not improve from 1.00000\n",
      "85/85 [==============================] - 1s 16ms/step - loss: 1.9456e-06 - acc: 1.0000 - val_loss: 0.0031 - val_acc: 0.9967 - lr: 2.5000e-04\n",
      "Epoch 141/200\n",
      "83/85 [============================>.] - ETA: 0s - loss: 1.9032e-06 - acc: 1.0000\n",
      "Epoch 141: val_acc did not improve from 1.00000\n",
      "85/85 [==============================] - 2s 19ms/step - loss: 1.8991e-06 - acc: 1.0000 - val_loss: 0.0031 - val_acc: 0.9967 - lr: 2.5000e-04\n",
      "Epoch 142/200\n",
      "84/85 [============================>.] - ETA: 0s - loss: 1.8309e-06 - acc: 1.0000\n",
      "Epoch 142: val_acc did not improve from 1.00000\n",
      "85/85 [==============================] - 2s 18ms/step - loss: 1.8256e-06 - acc: 1.0000 - val_loss: 0.0018 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 143/200\n",
      "82/85 [===========================>..] - ETA: 0s - loss: 1.7486e-06 - acc: 1.0000\n",
      "Epoch 143: val_acc did not improve from 1.00000\n",
      "85/85 [==============================] - 2s 19ms/step - loss: 1.7397e-06 - acc: 1.0000 - val_loss: 0.0029 - val_acc: 0.9967 - lr: 2.5000e-04\n",
      "Epoch 144/200\n",
      "82/85 [===========================>..] - ETA: 0s - loss: 1.6730e-06 - acc: 1.0000\n",
      "Epoch 144: val_acc did not improve from 1.00000\n",
      "85/85 [==============================] - 2s 19ms/step - loss: 1.6731e-06 - acc: 1.0000 - val_loss: 0.0034 - val_acc: 0.9967 - lr: 2.5000e-04\n",
      "Epoch 145/200\n",
      "83/85 [============================>.] - ETA: 0s - loss: 1.5750e-06 - acc: 1.0000\n",
      "Epoch 145: val_acc did not improve from 1.00000\n",
      "85/85 [==============================] - 2s 18ms/step - loss: 1.6029e-06 - acc: 1.0000 - val_loss: 0.0032 - val_acc: 0.9967 - lr: 2.5000e-04\n",
      "Epoch 146/200\n",
      "85/85 [==============================] - ETA: 0s - loss: 1.5485e-06 - acc: 1.0000\n",
      "Epoch 146: val_acc did not improve from 1.00000\n",
      "85/85 [==============================] - 1s 16ms/step - loss: 1.5485e-06 - acc: 1.0000 - val_loss: 0.0027 - val_acc: 0.9967 - lr: 2.5000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 147/200\n",
      "83/85 [============================>.] - ETA: 0s - loss: 1.4712e-06 - acc: 1.0000\n",
      "Epoch 147: val_acc did not improve from 1.00000\n",
      "85/85 [==============================] - 1s 16ms/step - loss: 1.4881e-06 - acc: 1.0000 - val_loss: 0.0039 - val_acc: 0.9967 - lr: 2.5000e-04\n",
      "Epoch 148/200\n",
      "84/85 [============================>.] - ETA: 0s - loss: 1.4464e-06 - acc: 1.0000\n",
      "Epoch 148: val_acc did not improve from 1.00000\n",
      "85/85 [==============================] - 1s 16ms/step - loss: 1.4421e-06 - acc: 1.0000 - val_loss: 0.0051 - val_acc: 0.9967 - lr: 2.5000e-04\n",
      "Epoch 149/200\n",
      "85/85 [==============================] - ETA: 0s - loss: 1.3380e-06 - acc: 1.0000\n",
      "Epoch 149: val_acc did not improve from 1.00000\n",
      "85/85 [==============================] - 1s 16ms/step - loss: 1.3380e-06 - acc: 1.0000 - val_loss: 8.3317e-04 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 150/200\n",
      "84/85 [============================>.] - ETA: 0s - loss: 1.3292e-06 - acc: 1.0000\n",
      "Epoch 150: val_acc did not improve from 1.00000\n",
      "85/85 [==============================] - 1s 16ms/step - loss: 1.3330e-06 - acc: 1.0000 - val_loss: 0.0021 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 151/200\n",
      "85/85 [==============================] - ETA: 0s - loss: 1.2906e-06 - acc: 1.0000\n",
      "Epoch 151: val_acc did not improve from 1.00000\n",
      "85/85 [==============================] - 1s 18ms/step - loss: 1.2906e-06 - acc: 1.0000 - val_loss: 0.0037 - val_acc: 0.9967 - lr: 2.5000e-04\n",
      "Epoch 152/200\n",
      "84/85 [============================>.] - ETA: 0s - loss: 1.2015e-06 - acc: 1.0000\n",
      "Epoch 152: val_acc did not improve from 1.00000\n",
      "85/85 [==============================] - 1s 17ms/step - loss: 1.2229e-06 - acc: 1.0000 - val_loss: 0.0030 - val_acc: 0.9967 - lr: 2.5000e-04\n",
      "Epoch 153/200\n",
      "82/85 [===========================>..] - ETA: 0s - loss: 1.2154e-06 - acc: 1.0000\n",
      "Epoch 153: val_acc did not improve from 1.00000\n",
      "85/85 [==============================] - 1s 17ms/step - loss: 1.1852e-06 - acc: 1.0000 - val_loss: 0.0013 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 154/200\n",
      "85/85 [==============================] - ETA: 0s - loss: 1.1295e-06 - acc: 1.0000\n",
      "Epoch 154: val_acc did not improve from 1.00000\n",
      "85/85 [==============================] - 2s 18ms/step - loss: 1.1295e-06 - acc: 1.0000 - val_loss: 0.0026 - val_acc: 0.9967 - lr: 2.5000e-04\n",
      "Epoch 155/200\n",
      "83/85 [============================>.] - ETA: 0s - loss: 1.0867e-06 - acc: 1.0000\n",
      "Epoch 155: val_acc did not improve from 1.00000\n",
      "85/85 [==============================] - 1s 17ms/step - loss: 1.0793e-06 - acc: 1.0000 - val_loss: 0.0030 - val_acc: 0.9967 - lr: 2.5000e-04\n",
      "Epoch 156/200\n",
      "84/85 [============================>.] - ETA: 0s - loss: 1.0446e-06 - acc: 1.0000\n",
      "Epoch 156: val_acc did not improve from 1.00000\n",
      "85/85 [==============================] - 1s 16ms/step - loss: 1.0416e-06 - acc: 1.0000 - val_loss: 6.6734e-04 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 157/200\n",
      "84/85 [============================>.] - ETA: 0s - loss: 1.0280e-06 - acc: 1.0000\n",
      "Epoch 157: val_acc did not improve from 1.00000\n",
      "85/85 [==============================] - 1s 17ms/step - loss: 1.0321e-06 - acc: 1.0000 - val_loss: 0.0032 - val_acc: 0.9967 - lr: 2.5000e-04\n",
      "Epoch 158/200\n",
      "85/85 [==============================] - ETA: 0s - loss: 9.6514e-07 - acc: 1.0000\n",
      "Epoch 158: val_acc did not improve from 1.00000\n",
      "85/85 [==============================] - 1s 16ms/step - loss: 9.6514e-07 - acc: 1.0000 - val_loss: 0.0027 - val_acc: 0.9967 - lr: 2.5000e-04\n",
      "Epoch 159/200\n",
      "85/85 [==============================] - ETA: 0s - loss: 9.2509e-07 - acc: 1.0000\n",
      "Epoch 159: val_acc did not improve from 1.00000\n",
      "85/85 [==============================] - 1s 16ms/step - loss: 9.2509e-07 - acc: 1.0000 - val_loss: 0.0017 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 160/200\n",
      "85/85 [==============================] - ETA: 0s - loss: 9.0413e-07 - acc: 1.0000\n",
      "Epoch 160: val_acc did not improve from 1.00000\n",
      "85/85 [==============================] - 1s 16ms/step - loss: 9.0413e-07 - acc: 1.0000 - val_loss: 0.0021 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 161/200\n",
      "84/85 [============================>.] - ETA: 0s - loss: 8.6229e-07 - acc: 1.0000\n",
      "Epoch 161: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 161: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "85/85 [==============================] - 1s 17ms/step - loss: 8.6133e-07 - acc: 1.0000 - val_loss: 6.5489e-04 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 162/200\n",
      "84/85 [============================>.] - ETA: 0s - loss: 8.5866e-07 - acc: 1.0000\n",
      "Epoch 162: val_acc did not improve from 1.00000\n",
      "85/85 [==============================] - 1s 17ms/step - loss: 8.5637e-07 - acc: 1.0000 - val_loss: 0.0016 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 163/200\n",
      "83/85 [============================>.] - ETA: 0s - loss: 8.2749e-07 - acc: 1.0000\n",
      "Epoch 163: val_acc did not improve from 1.00000\n",
      "85/85 [==============================] - 1s 17ms/step - loss: 8.2233e-07 - acc: 1.0000 - val_loss: 0.0018 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 164/200\n",
      "84/85 [============================>.] - ETA: 0s - loss: 8.0686e-07 - acc: 1.0000\n",
      "Epoch 164: val_acc did not improve from 1.00000\n",
      "85/85 [==============================] - 1s 16ms/step - loss: 8.0447e-07 - acc: 1.0000 - val_loss: 0.0023 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 165/200\n",
      "85/85 [==============================] - ETA: 0s - loss: 7.8638e-07 - acc: 1.0000\n",
      "Epoch 165: val_acc did not improve from 1.00000\n",
      "85/85 [==============================] - 1s 16ms/step - loss: 7.8638e-07 - acc: 1.0000 - val_loss: 0.0021 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 166/200\n",
      "84/85 [============================>.] - ETA: 0s - loss: 7.7294e-07 - acc: 1.0000\n",
      "Epoch 166: val_acc did not improve from 1.00000\n",
      "85/85 [==============================] - 1s 17ms/step - loss: 7.7091e-07 - acc: 1.0000 - val_loss: 0.0034 - val_acc: 0.9967 - lr: 1.2500e-04\n",
      "Epoch 167/200\n",
      "85/85 [==============================] - ETA: 0s - loss: 7.5234e-07 - acc: 1.0000\n",
      "Epoch 167: val_acc did not improve from 1.00000\n",
      "85/85 [==============================] - 1s 17ms/step - loss: 7.5234e-07 - acc: 1.0000 - val_loss: 0.0026 - val_acc: 0.9967 - lr: 1.2500e-04\n",
      "Epoch 168/200\n",
      "85/85 [==============================] - ETA: 0s - loss: 7.3761e-07 - acc: 1.0000\n",
      "Epoch 168: val_acc did not improve from 1.00000\n",
      "85/85 [==============================] - 1s 17ms/step - loss: 7.3761e-07 - acc: 1.0000 - val_loss: 0.0029 - val_acc: 0.9967 - lr: 1.2500e-04\n",
      "Epoch 169/200\n",
      "84/85 [============================>.] - ETA: 0s - loss: 7.2194e-07 - acc: 1.0000\n",
      "Epoch 169: val_acc did not improve from 1.00000\n",
      "85/85 [==============================] - 1s 16ms/step - loss: 7.1979e-07 - acc: 1.0000 - val_loss: 0.0033 - val_acc: 0.9967 - lr: 1.2500e-04\n",
      "Epoch 170/200\n",
      "83/85 [============================>.] - ETA: 0s - loss: 7.1681e-07 - acc: 1.0000\n",
      "Epoch 170: val_acc did not improve from 1.00000\n",
      "85/85 [==============================] - 1s 17ms/step - loss: 7.1055e-07 - acc: 1.0000 - val_loss: 0.0024 - val_acc: 0.9967 - lr: 1.2500e-04\n",
      "Epoch 171/200\n",
      "85/85 [==============================] - ETA: 0s - loss: 6.9296e-07 - acc: 1.0000\n",
      "Epoch 171: val_acc did not improve from 1.00000\n",
      "85/85 [==============================] - 1s 17ms/step - loss: 6.9296e-07 - acc: 1.0000 - val_loss: 0.0017 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 172/200\n",
      "83/85 [============================>.] - ETA: 0s - loss: 6.8162e-07 - acc: 1.0000\n",
      "Epoch 172: val_acc did not improve from 1.00000\n",
      "85/85 [==============================] - 1s 17ms/step - loss: 6.7695e-07 - acc: 1.0000 - val_loss: 0.0021 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 173/200\n",
      "85/85 [==============================] - ETA: 0s - loss: 6.5537e-07 - acc: 1.0000\n",
      "Epoch 173: val_acc did not improve from 1.00000\n",
      "85/85 [==============================] - 1s 17ms/step - loss: 6.5537e-07 - acc: 1.0000 - val_loss: 0.0020 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 174/200\n",
      "83/85 [============================>.] - ETA: 0s - loss: 6.4612e-07 - acc: 1.0000\n",
      "Epoch 174: val_acc did not improve from 1.00000\n",
      "85/85 [==============================] - 1s 16ms/step - loss: 6.4971e-07 - acc: 1.0000 - val_loss: 0.0013 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 175/200\n",
      "84/85 [============================>.] - ETA: 0s - loss: 6.3311e-07 - acc: 1.0000\n",
      "Epoch 175: val_acc did not improve from 1.00000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85/85 [==============================] - 1s 17ms/step - loss: 6.3123e-07 - acc: 1.0000 - val_loss: 0.0026 - val_acc: 0.9967 - lr: 1.2500e-04\n",
      "Epoch 176/200\n",
      "84/85 [============================>.] - ETA: 0s - loss: 6.1333e-07 - acc: 1.0000\n",
      "Epoch 176: val_acc did not improve from 1.00000\n",
      "85/85 [==============================] - 1s 17ms/step - loss: 6.1151e-07 - acc: 1.0000 - val_loss: 0.0029 - val_acc: 0.9967 - lr: 1.2500e-04\n",
      "Epoch 177/200\n",
      "83/85 [============================>.] - ETA: 0s - loss: 5.8504e-07 - acc: 1.0000\n",
      "Epoch 177: val_acc did not improve from 1.00000\n",
      "85/85 [==============================] - 1s 17ms/step - loss: 5.9528e-07 - acc: 1.0000 - val_loss: 0.0023 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 178/200\n",
      "82/85 [===========================>..] - ETA: 0s - loss: 5.9290e-07 - acc: 1.0000\n",
      "Epoch 178: val_acc did not improve from 1.00000\n",
      "85/85 [==============================] - 1s 16ms/step - loss: 5.8609e-07 - acc: 1.0000 - val_loss: 0.0026 - val_acc: 0.9967 - lr: 1.2500e-04\n",
      "Epoch 179/200\n",
      "83/85 [============================>.] - ETA: 0s - loss: 5.6287e-07 - acc: 1.0000\n",
      "Epoch 179: val_acc did not improve from 1.00000\n",
      "85/85 [==============================] - 1s 16ms/step - loss: 5.6539e-07 - acc: 1.0000 - val_loss: 0.0022 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 180/200\n",
      "84/85 [============================>.] - ETA: 0s - loss: 5.5612e-07 - acc: 1.0000\n",
      "Epoch 180: val_acc did not improve from 1.00000\n",
      "85/85 [==============================] - 1s 17ms/step - loss: 5.5447e-07 - acc: 1.0000 - val_loss: 0.0023 - val_acc: 0.9967 - lr: 1.2500e-04\n",
      "Epoch 181/200\n",
      "85/85 [==============================] - ETA: 0s - loss: 5.3480e-07 - acc: 1.0000\n",
      "Epoch 181: val_acc did not improve from 1.00000\n",
      "85/85 [==============================] - 1s 17ms/step - loss: 5.3480e-07 - acc: 1.0000 - val_loss: 0.0022 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 182/200\n",
      "85/85 [==============================] - ETA: 0s - loss: 5.2352e-07 - acc: 1.0000\n",
      "Epoch 182: val_acc did not improve from 1.00000\n",
      "85/85 [==============================] - 1s 16ms/step - loss: 5.2352e-07 - acc: 1.0000 - val_loss: 0.0024 - val_acc: 0.9967 - lr: 1.2500e-04\n",
      "Epoch 183/200\n",
      "85/85 [==============================] - ETA: 0s - loss: 5.0513e-07 - acc: 1.0000\n",
      "Epoch 183: val_acc did not improve from 1.00000\n",
      "85/85 [==============================] - 1s 16ms/step - loss: 5.0513e-07 - acc: 1.0000 - val_loss: 0.0020 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 184/200\n",
      "84/85 [============================>.] - ETA: 0s - loss: 4.9297e-07 - acc: 1.0000\n",
      "Epoch 184: val_acc did not improve from 1.00000\n",
      "85/85 [==============================] - 1s 16ms/step - loss: 4.9169e-07 - acc: 1.0000 - val_loss: 0.0023 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 185/200\n",
      "84/85 [============================>.] - ETA: 0s - loss: 4.9949e-07 - acc: 1.0000\n",
      "Epoch 185: val_acc did not improve from 1.00000\n",
      "85/85 [==============================] - 1s 16ms/step - loss: 4.9801e-07 - acc: 1.0000 - val_loss: 0.0014 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 186/200\n",
      "85/85 [==============================] - ETA: 0s - loss: 4.6175e-07 - acc: 1.0000\n",
      "Epoch 186: val_acc did not improve from 1.00000\n",
      "85/85 [==============================] - 1s 16ms/step - loss: 4.6175e-07 - acc: 1.0000 - val_loss: 0.0022 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 187/200\n",
      "83/85 [============================>.] - ETA: 0s - loss: 4.4622e-07 - acc: 1.0000\n",
      "Epoch 187: val_acc did not improve from 1.00000\n",
      "85/85 [==============================] - 1s 17ms/step - loss: 4.4787e-07 - acc: 1.0000 - val_loss: 0.0031 - val_acc: 0.9967 - lr: 1.2500e-04\n",
      "Epoch 188/200\n",
      "82/85 [===========================>..] - ETA: 0s - loss: 4.1209e-07 - acc: 1.0000\n",
      "Epoch 188: val_acc did not improve from 1.00000\n",
      "85/85 [==============================] - 1s 16ms/step - loss: 4.2470e-07 - acc: 1.0000 - val_loss: 0.0033 - val_acc: 0.9967 - lr: 1.2500e-04\n",
      "Epoch 189/200\n",
      "84/85 [============================>.] - ETA: 0s - loss: 4.0947e-07 - acc: 1.0000\n",
      "Epoch 189: val_acc did not improve from 1.00000\n",
      "85/85 [==============================] - 1s 16ms/step - loss: 4.0834e-07 - acc: 1.0000 - val_loss: 9.2929e-04 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 190/200\n",
      "83/85 [============================>.] - ETA: 0s - loss: 3.9111e-07 - acc: 1.0000\n",
      "Epoch 190: val_acc did not improve from 1.00000\n",
      "85/85 [==============================] - 1s 17ms/step - loss: 3.9229e-07 - acc: 1.0000 - val_loss: 0.0017 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 191/200\n",
      "84/85 [============================>.] - ETA: 0s - loss: 3.7714e-07 - acc: 1.0000\n",
      "Epoch 191: val_acc did not improve from 1.00000\n",
      "85/85 [==============================] - 1s 17ms/step - loss: 3.7646e-07 - acc: 1.0000 - val_loss: 9.9794e-04 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 192/200\n",
      "83/85 [============================>.] - ETA: 0s - loss: 3.6875e-07 - acc: 1.0000\n",
      "Epoch 192: val_acc did not improve from 1.00000\n",
      "85/85 [==============================] - 1s 17ms/step - loss: 3.6359e-07 - acc: 1.0000 - val_loss: 0.0016 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 193/200\n",
      "85/85 [==============================] - ETA: 0s - loss: 3.4882e-07 - acc: 1.0000\n",
      "Epoch 193: val_acc did not improve from 1.00000\n",
      "85/85 [==============================] - 1s 17ms/step - loss: 3.4882e-07 - acc: 1.0000 - val_loss: 0.0018 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 194/200\n",
      "84/85 [============================>.] - ETA: 0s - loss: 3.3376e-07 - acc: 1.0000\n",
      "Epoch 194: val_acc did not improve from 1.00000\n",
      "85/85 [==============================] - 1s 16ms/step - loss: 3.3277e-07 - acc: 1.0000 - val_loss: 0.0025 - val_acc: 0.9967 - lr: 1.2500e-04\n",
      "Epoch 195/200\n",
      "85/85 [==============================] - ETA: 0s - loss: 3.2981e-07 - acc: 1.0000\n",
      "Epoch 195: val_acc did not improve from 1.00000\n",
      "85/85 [==============================] - 1s 16ms/step - loss: 3.2981e-07 - acc: 1.0000 - val_loss: 0.0013 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 196/200\n",
      "84/85 [============================>.] - ETA: 0s - loss: 3.0525e-07 - acc: 1.0000\n",
      "Epoch 196: val_acc did not improve from 1.00000\n",
      "85/85 [==============================] - 1s 16ms/step - loss: 3.0439e-07 - acc: 1.0000 - val_loss: 0.0017 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 197/200\n",
      "82/85 [===========================>..] - ETA: 0s - loss: 2.9988e-07 - acc: 1.0000\n",
      "Epoch 197: val_acc did not improve from 1.00000\n",
      "85/85 [==============================] - 1s 17ms/step - loss: 2.9254e-07 - acc: 1.0000 - val_loss: 0.0019 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 198/200\n",
      "83/85 [============================>.] - ETA: 0s - loss: 2.8720e-07 - acc: 1.0000\n",
      "Epoch 198: val_acc did not improve from 1.00000\n",
      "85/85 [==============================] - 1s 17ms/step - loss: 2.8299e-07 - acc: 1.0000 - val_loss: 0.0023 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 199/200\n",
      "83/85 [============================>.] - ETA: 0s - loss: 2.7715e-07 - acc: 1.0000\n",
      "Epoch 199: val_acc did not improve from 1.00000\n",
      "85/85 [==============================] - 1s 17ms/step - loss: 2.7485e-07 - acc: 1.0000 - val_loss: 0.0018 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 200/200\n",
      "85/85 [==============================] - ETA: 0s - loss: 2.6570e-07 - acc: 1.0000\n",
      "Epoch 200: val_acc did not improve from 1.00000\n",
      "85/85 [==============================] - 1s 17ms/step - loss: 2.6570e-07 - acc: 1.0000 - val_loss: 0.0024 - val_acc: 0.9967 - lr: 1.2500e-04\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "history = model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    validation_data=(x_val, y_val),\n",
    "    epochs=200,\n",
    "    callbacks=[\n",
    "        ModelCheckpoint('models/model.h5', monitor='val_acc', verbose=1, save_best_only=True, mode='auto'),\n",
    "        ReduceLROnPlateau(monitor='val_acc', factor=0.5, patience=50, verbose=1, mode='auto')\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, loss_ax = plt.subplots(figsize=(16, 10))\n",
    "acc_ax = loss_ax.twinx()\n",
    "\n",
    "loss_ax.plot(history.history['loss'], 'y', label='train loss')\n",
    "loss_ax.plot(history.history['val_loss'], 'r', label='val loss')\n",
    "loss_ax.set_xlabel('epoch')\n",
    "loss_ax.set_ylabel('loss')\n",
    "loss_ax.legend(loc='upper left')\n",
    "\n",
    "acc_ax.plot(history.history['acc'], 'b', label='train acc')\n",
    "acc_ax.plot(history.history['val_acc'], 'g', label='val acc')\n",
    "acc_ax.set_ylabel('accuracy')\n",
    "acc_ax.legend(loc='upper left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 9ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[199,   0],\n",
       "        [  0, 101]],\n",
       "\n",
       "       [[179,   0],\n",
       "        [  0, 121]],\n",
       "\n",
       "       [[222,   0],\n",
       "        [  0,  78]]], dtype=int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model = load_model('models/model.h5')\n",
    "\n",
    "y_pred = model.predict(x_val)\n",
    "\n",
    "multilabel_confusion_matrix(np.argmax(y_val, axis=1), np.argmax(y_pred, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
